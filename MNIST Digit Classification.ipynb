{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYhapkxz48x0"
      },
      "source": [
        "# CNN for MNIST Handwritten Digit Classification\n",
        "**Author:** Khai Ta  \n",
        "**Date:** October 2024\n",
        "\n",
        "In this project, I implement a Convolutional Neural Network (CNN) to classify handwritten digits from the MNIST dataset using PyTorch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI7HNJEH9EmV"
      },
      "source": [
        "## 1. Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Pw5AIpt5gFC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKVteUX65INR"
      },
      "source": [
        "## 2. Loading the MNIST Dataset\n",
        "\n",
        "We use the `torchvision` library to download and load the MNIST dataset, which consists of 28x28 grayscale images of handwritten digits (0-9). We create training and testing datasets and use `DataLoader` for batching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2DRVmar6USq",
        "outputId": "37fe52cb-139c-48ab-da87-645366394a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.0MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 477kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.37MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.39MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_data = datasets.MNIST(root='data', train=True, transform=ToTensor(), download=True)\n",
        "test_data = datasets.MNIST(root='data', train=False, transform=ToTensor(), download=True)\n",
        "\n",
        "loaders = {\n",
        "    'train': DataLoader(train_data, batch_size=100, shuffle=True, num_workers=1),\n",
        "    'test': DataLoader(test_data, batch_size=100, shuffle=False, num_workers=1),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RhGHjDe5XBz"
      },
      "source": [
        "## 3. Defining the CNN Model\n",
        "\n",
        "We define a CNN model that includes two convolutional layers, dropout for regularization, and two fully connected layers for classification. The model uses ReLU activations and outputs log probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmly4-Kl84-X"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmUl1OBS5k3O"
      },
      "source": [
        "## 4. Setting Up the Training Environment\n",
        "\n",
        "We check if a GPU is available for faster computations. We also define the optimizer (Adam) and the loss function (CrossEntropyLoss)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jz2THQFQ9dr1"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADhVaXnM5svy"
      },
      "source": [
        "## 5. Training the Model\n",
        "\n",
        "We implement a training loop where the model is trained for a specified number of epochs. During training, we print the loss every 50 batches to monitor progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSYqUWPxcczz"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 50 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} '\n",
        "                  f'({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\tLoss: {loss.item():.6f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XKCLQmT5-PH"
      },
      "source": [
        "## 6. Testing the Model\n",
        "\n",
        "After training, we evaluate the model on the test dataset, calculating the average loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "76Ar_wvag_xv"
      },
      "outputs": [],
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in loaders['test']:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += loss_fn(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(loaders['test'])\n",
        "    accuracy = 100. * correct / len(loaders['test'].dataset)\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders[\"test\"].dataset)} '\n",
        "          f'({accuracy:.0f}%)\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjtOUxMb6HtL"
      },
      "source": [
        "## 7. Training and Evaluating the Model\n",
        "\n",
        "We train the model for 10 epochs and evaluate its performance on the test set after each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTcjAWae6FG-",
        "outputId": "12b7d3c3-a179-4608-d47d-4ee837cd6944"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300922\n",
            "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 1.352119\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.658842\n",
            "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.753340\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.431108\n",
            "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.524499\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.446015\n",
            "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.328297\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.304909\n",
            "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.560231\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.329533\n",
            "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.215860\n",
            "\n",
            "Test set: Average loss: 0.1309, Accuracy: 9592/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.315657\n",
            "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.238810\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.263194\n",
            "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.408566\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.235147\n",
            "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.260243\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.301017\n",
            "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.295686\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.279301\n",
            "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.384326\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.376336\n",
            "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.196473\n",
            "\n",
            "Test set: Average loss: 0.0924, Accuracy: 9709/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.306155\n",
            "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.335616\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.240572\n",
            "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.196036\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.228402\n",
            "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.266506\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.291593\n",
            "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.178392\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.328409\n",
            "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.245630\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.288744\n",
            "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.172775\n",
            "\n",
            "Test set: Average loss: 0.0757, Accuracy: 9773/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.179286\n",
            "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.167249\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.205990\n",
            "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.312046\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.204757\n",
            "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.182487\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.204611\n",
            "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.169400\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.313621\n",
            "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.225466\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.187765\n",
            "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.304035\n",
            "\n",
            "Test set: Average loss: 0.0647, Accuracy: 9808/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.099069\n",
            "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.121720\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.382820\n",
            "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.102654\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.172730\n",
            "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.175513\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.276246\n",
            "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.212299\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.177525\n",
            "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.092138\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.091549\n",
            "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.092245\n",
            "\n",
            "Test set: Average loss: 0.0615, Accuracy: 9813/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.237805\n",
            "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 0.207517\n",
            "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.218804\n",
            "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 0.159569\n",
            "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.192435\n",
            "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 0.213920\n",
            "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.316337\n",
            "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 0.186288\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.186352\n",
            "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 0.291779\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.099685\n",
            "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 0.168951\n",
            "\n",
            "Test set: Average loss: 0.0595, Accuracy: 9821/10000 (98%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.176926\n",
            "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 0.180636\n",
            "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.162395\n",
            "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 0.123817\n",
            "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.176227\n",
            "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 0.095223\n",
            "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.101400\n",
            "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 0.227793\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.238248\n",
            "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 0.238245\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.153390\n",
            "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 0.259760\n",
            "\n",
            "Test set: Average loss: 0.0494, Accuracy: 9845/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.185882\n",
            "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 0.156813\n",
            "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.127585\n",
            "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 0.270200\n",
            "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.261229\n",
            "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 0.200452\n",
            "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.124877\n",
            "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 0.140819\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.213732\n",
            "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 0.129158\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.235566\n",
            "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 0.147697\n",
            "\n",
            "Test set: Average loss: 0.0500, Accuracy: 9847/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.093650\n",
            "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 0.136131\n",
            "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.083923\n",
            "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 0.191477\n",
            "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.219367\n",
            "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 0.135800\n",
            "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.207980\n",
            "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 0.312249\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.108023\n",
            "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 0.163298\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.306170\n",
            "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 0.188395\n",
            "\n",
            "Test set: Average loss: 0.0463, Accuracy: 9854/10000 (99%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.164741\n",
            "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 0.284131\n",
            "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.186347\n",
            "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 0.070318\n",
            "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.170663\n",
            "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 0.167965\n",
            "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.150931\n",
            "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 0.111757\n",
            "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.209384\n",
            "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 0.153236\n",
            "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.144034\n",
            "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 0.097626\n",
            "\n",
            "Test set: Average loss: 0.0453, Accuracy: 9857/10000 (99%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, 11):\n",
        "    train(epoch)\n",
        "    test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiPxEN9W6LYO"
      },
      "source": [
        "## 8. Visualizing Predictions\n",
        "\n",
        "We can visualize the model's predictions on individual test images to assess its performance qualitatively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "sNrAA64-6LzF",
        "outputId": "54ea4a84-06ab-4658-8bc9-431e5700486f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: 0\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def predict_single_image(index):\n",
        "    model.eval()\n",
        "    data, target = test_data[index]\n",
        "    data = data.unsqueeze(0).to(device)\n",
        "\n",
        "    output = model(data)\n",
        "    prediction = output.argmax(dim=1, keepdim=True).item()\n",
        "    print(f'Prediction: {prediction}')\n",
        "\n",
        "    image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.title(f'Predicted: {prediction}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "predict_single_image(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbqbRQc06Oz7"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "We successfully built and trained a Convolutional Neural Network (CNN) to classify handwritten digits from the MNIST dataset. The model achieved an accuracy of approximately 99%, demonstrating the effectiveness of CNNs in image classification tasks."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}